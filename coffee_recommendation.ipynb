{"cells":[{"cell_type":"markdown","metadata":{},"source":["Final Project Submission <br>\n","Student name: Qilun Chen, Evan Serrano<br>\n","Student pace: full time<br>\n","Scheduled project review date/time: April/1/2022<br>\n","Instructor name: Praveen Gowtham, Joe Comeaux<br>\n","Blog post URL:https://github.com/nkbuddy/dsc-phase-3-project-NBA"]},{"cell_type":"markdown","metadata":{},"source":["### Table of Contents\n","* [STEP 1: Define the Problem](#Define-the-Problem)\n","* [Step 2: Gather the Data](#Gather-the-Data)\n","* [Step 3: Prepare Data for Consumption](#Prepare-Data-for-Consumption)\n","    * [3.1 Import Libraries](#Import-Libraries)\n","        * [3.11 Load Data Modelling Libraries](#Load-Data-Modelling-Libraries)\n","    * [3.2 Meet and Greet Data](#Meet-and-Greet-Data)\n","        * [3.21 The 4 C's of Data Cleaning: Correcting, Completing, Creating, and Converting](#4C)\n","        * [3.22 Clean Data](#Clean-Data)\n","        * [3.23 Convert Formats](#Convert-Formats)\n","        * [3.24 Da-Double Check Cleaned Data](#Da-Double-Check-Cleaned-Data)\n","        * [3.25 Split Training and Testing Data](#Split-Training-and-Testing-Data)\n","* [Step 4: Perform Exploratory Analysis with Statistics](#Perform-Exploratory-Analysis-with-Statistics)\n","* [Step 5: Model Data](#Model-Data)\n","    * [5.1 Evaluate Model Performance](#Evaluate-Model-Performance)\n","        * [5.11 Model Performance with Cross-Validation (CV)](#CV)\n","        * [5.12 Tune Model with Hyper-Parameters](#Tune-Model-with-Hyper-Parameters)\n","        * [5.13 Tune Model with Feature Selection](#Tune-Model-with-Feature-Selection)\n","* [Step 6: Validate and Implement](#Validate-and-Implement)\n","* [STEP 7: Optimize and Strategize](#Optimize-and-Strategize)"]},{"cell_type":"markdown","metadata":{},"source":["# STEP 1: Define the Problem <a class=\"anchor\" id=\"Define-the-Problem\"></a>"]},{"cell_type":"markdown","metadata":{},"source":["Giving a recommendation to people who has favortie coffee but wants to try sometings news."]},{"cell_type":"markdown","metadata":{},"source":["# Step 2: Gather the Data <a class=\"anchor\" id=\"Gather-the-Data\"></a>"]},{"cell_type":"markdown","metadata":{},"source":["Web scraping from coffeereview.com"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["import requests\n","from bs4 import BeautifulSoup\n","import pandas as pd\n","import numpy as np\n","import numpy as np\n","import PIL.ImageFile as ImageFile\n","import random"]},{"cell_type":"code","execution_count":44,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Costa Rica Naranjo Danilo Salazar Arias\n","Kenya Kahunyo AA\n","Honduras COMSA Oscar Omar Alonzo\n","Rwanda Gasharu Natural\n","Yemen Haraaz Red Mahal Aqeeq ul Station Natural\n","Sítio Pedra Menina\n","Brazil Sítio Ponte Fazenda Ponte\n","Brazil Legender Sitio Taquara Natural\n","Ethiopia Odola Washed\n","Minanga Village Sulawesi\n","Ka‘ū Tropical Punch Washed\n","Birambo Village DR Congo\n","Kenya Kamgogo Small Lot Reserve\n","Ethiopia Belayneh Bariso Natural\n","Kuta Kofi Papua New Guinea\n","Rwanda Gatare Natural\n","Rock the House Blend\n","Kona SL34 Champagne Natural Uluwehi Farm\n","Yemen Al Mashtal Al Burhani\n","Ka‘ū Lactic Natural\n"]}],"source":["from urllib.request import Request, urlopen\n","from bs4 import BeautifulSoup as soup\n","url = 'https://www.coffeereview.com/review/?locations=na'\n","req = Request(url , headers={'User-Agent': 'Mozilla/5.0'})\n","\n","webpage = urlopen(req).read()\n","page_soup = soup(webpage, \"html.parser\")\n","containers = page_soup.findAll(\"p\",\"review-title\")\n","for container in containers:\n","    print(container.text)"]},{"cell_type":"code","execution_count":61,"metadata":{},"outputs":[],"source":["url_each_coffee = []\n","for i in range(1,289):\n","    if i == 1:\n","        url = \"https://www.coffeereview.com/review/?locations=na\"\n","    else:\n","        url=\"https://www.coffeereview.com/review/page/\"+str(i)+\"/?locations=na\"\n","    req = Request(url , headers={'User-Agent': 'Mozilla/5.0'})\n","    webpage = urlopen(req).read()\n","    page_soup = soup(webpage, \"html.parser\")\n","    containers = page_soup.findAll(\"p\",\"review-title\")\n","    for container in containers:\n","        url_each_coffee.append(container.a['href'])"]},{"cell_type":"code","execution_count":62,"metadata":{},"outputs":[{"data":{"text/plain":["'https://www.coffeereview.com/review/costa-rica-naranjo-danilo-salazar-arias/'"]},"execution_count":62,"metadata":{},"output_type":"execute_result"}],"source":["url_each_coffee[0]"]},{"cell_type":"code","execution_count":75,"metadata":{},"outputs":[{"data":{"text/plain":["5746"]},"execution_count":75,"metadata":{},"output_type":"execute_result"}],"source":["len(url_each_coffee)"]},{"cell_type":"code","execution_count":365,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["94\n","Coffee by Design\n","Costa Rica Naranjo Danilo Salazar Arias\n","Portland, Maine\n","Alajuela, Costa Rica\n","Medium-Light\n","60/77\n","$23.00/12 ounces\n","May 2022\n","9\n","9\n","9\t\t\t\t\t\t\t\n","9\n","8\n","[<p class=\"review-roaster\">Coffee by Design</p>, <p><strong>Blind Assessment: </strong>Bright, richly sweet-tart, fruit-toned. Pomegranate, dark chocolate, lilac, almond, amber in aroma and small cup. Bright structure with juicy, vibrant acidity; plush, creamy mouthfeel. Sweetly tart finish with leading notes of pomegranate and almond. Crisply chocolaty, floral finish.\n","</p>, <p><strong>Notes: </strong>Produced by Danilo Salazar Arias of San Cristobal Farm, from the Catuai, Caturra and Villa Sarchi varieties of Arabica, and processed by the natural method (dried in the whole fruit). Founded in 1994, Coffee By Design is a specialty coffee roaster in Portland, Maine that also operates three coffee shops in town, as well as one in Freeport. Visit www.coffeebydesign.com.\n","\n"," </p>, <p><strong>The Bottom Line:</strong> A lively, juicy-bright natural-processed Costa Rica cup with inviting fruit and floral notes throughout.\n","\n","</p>]\n"]}],"source":["url = url_each_coffee[0]\n","req = Request(url , headers={'User-Agent': 'Mozilla/5.0'})\n","\n","webpage = urlopen(req).read()\n","page_soup = soup(webpage, \"html.parser\")\n","coffee_rating = page_soup.findAll(\"span\",\"review-template-rating\")\n","for rating in coffee_rating:\n","    print(rating.text)\n","coffee_roaster = page_soup.findAll(\"p\",\"review-roaster\")\n","for roaster in coffee_roaster:\n","    print(roaster.text)\n","coffee_name = page_soup.findAll(\"h1\",\"review-title\")\n","for name in coffee_name:\n","    print(name.text)\n","coffee_table = page_soup.findAll(\"table\",\"review-template-table\")\n","for row in coffee_table:\n","    if \"Roaster Location:\" in row.find_all('td')[0]:\n","        print(row.find_all('td')[1].text)\n","    if \"Coffee Origin:\" in row.find_all('td')[2]:\n","        print(row.find_all('td')[3].text)\n","    if \"Roast Level:\" in row.find_all('td')[4]:\n","        print(row.find_all('td')[5].text)\n","    if \"Agtron:\" in row.find_all('td')[6]:\n","        print(row.find_all('td')[7].text)\n","    if \"Est. Price:\" in row.find_all('td')[8]:\n","        print(row.find_all('td')[9].text)\n","    if \"Review Date:\" in row.find_all('td')[0]:\n","        print(row.find_all('td')[1].text)\n","    if \"Aroma:\" in row.find_all('td')[2]:\n","        print(row.find_all('td')[3].text)\n","    if \"Acidity/Structure:\" in row.find_all('td')[4]:\n","        print(row.find_all('td')[5].text)\n","    if \"Body:\" in row.find_all('td')[6]:\n","        print(row.find_all('td')[7].text)\n","    if \"Flavor:\" in row.find_all('td')[8]:\n","        print(row.find_all('td')[9].text)\n","    if \"Aftertaste:\" in row.find_all('td')[-2]:\n","        print(row.find_all('td')[-1].text)\n","coffee_text = page_soup.findAll(\"div\",\"review-template\")\n","for name in coffee_text:\n","    print(name.find_all('p'))"]},{"cell_type":"code","execution_count":364,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["$23.00/12 ounces\n","8\n"]}],"source":["for row in coffee_table:\n","    print(row.find_all('td')[-1].text)"]},{"cell_type":"code","execution_count":366,"metadata":{},"outputs":[{"ename":"IndexError","evalue":"list index out of range","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-366-ae4d699e2401>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0magtron\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'td'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"Est. Price:\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'td'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m             \u001b[0mestimate_price\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'td'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mIndexError\u001b[0m: list index out of range"]}],"source":["coffee_score = []\n","coffee_roaster_name = []\n","coffee_bean_name = []\n","roaster_location = []\n","coffee_origin = []\n","roast_level = []\n","agtron = []\n","estimate_price = []\n","review_date=[]\n","aroma = []\n","acidity_or_structure = []\n","body = []\n","flavor = []\n","aftertaste = []\n","text=[]\n","for url in url_each_coffee:\n","    req = Request(url , headers={'User-Agent': 'Mozilla/5.0'})\n","\n","    webpage = urlopen(req).read()\n","    page_soup = soup(webpage, \"html.parser\")\n","\n","    coffee_rating = page_soup.findAll(\"span\",\"review-template-rating\")\n","    for rating in coffee_rating:\n","        coffee_score.append(rating.text)\n","\n","    coffee_roaster = page_soup.findAll(\"p\",\"review-roaster\")\n","    for roaster in coffee_roaster:\n","        coffee_roaster_name.append(roaster.text)\n","\n","    coffee_name = page_soup.findAll(\"h1\",\"review-title\")\n","    for name in coffee_name:\n","        coffee_bean_name.append(name.text)\n","\n","    coffee_table = page_soup.findAll(\"table\",\"review-template-table\")\n","    for row in coffee_table:\n","        if \"Roaster Location:\" in row.find_all('td')[0]:\n","            roaster_location.append(row.find_all('td')[1].text)\n","\n","        if \"Coffee Origin:\" in row.find_all('td')[2]:\n","            coffee_origin.append(row.find_all('td')[3].text)\n","\n","        if \"Roast Level:\" in row.find_all('td')[4]:\n","            roast_level.append(row.find_all('td')[5].text)\n","\n","        if \"Agtron:\" in row.find_all('td')[6]:\n","            agtron.append(row.find_all('td')[7].text)\n","\n","        if \"Est. Price:\" in row.find_all('td')[8]:\n","            estimate_price.append(row.find_all('td')[9].text)\n","\n","        if \"Review Date:\" in row.find_all('td')[0]:\n","            review_date.append(row.find_all('td')[1].text)\n","\n","        if \"Aroma:\" in row.find_all('td')[2]:\n","            aroma.append(row.find_all('td')[3].text)\n","\n","        if \"Acidity/Structure:\" in row.find_all('td')[4]:\n","            acidity_or_structure.append(row.find_all('td')[5].text)\n","\n","        if \"Body:\" in row.find_all('td')[6]:\n","            body.append(row.find_all('td')[7].text)\n","\n","        if \"Flavor:\" in row.find_all('td')[8]:\n","            flavor.append(row.find_all('td')[9].text)\n","\n","        if \"Aftertaste:\" in row.find_all('td')[-2]:\n","            aftertaste.append(row.find_all('td')[-1].text)\n","\n","    coffee_text = page_soup.findAll(\"div\",\"review-template\")\n","    for name in coffee_text:\n","        text.append(name.find_all('p'))\n"]},{"cell_type":"code","execution_count":369,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/Users/alanchan/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/pandas/core/internals/blocks.py:849: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n","  arr_value = np.array(value)\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>coffee_score</th>\n","      <th>coffee_roaster_name</th>\n","      <th>coffee_bean_name</th>\n","      <th>roaster_location</th>\n","      <th>coffee_origin</th>\n","      <th>roast_level</th>\n","      <th>agtron</th>\n","      <th>estimate_price</th>\n","      <th>review_date</th>\n","      <th>aroma</th>\n","      <th>acidity_or_structure</th>\n","      <th>body</th>\n","      <th>flavor</th>\n","      <th>aftertaste</th>\n","      <th>text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>94</td>\n","      <td>Coffee by Design</td>\n","      <td>Costa Rica Naranjo Danilo Salazar Arias</td>\n","      <td>Portland, Maine</td>\n","      <td>Alajuela, Costa Rica</td>\n","      <td>Medium-Light</td>\n","      <td>60/77</td>\n","      <td>$23.00/12 ounces</td>\n","      <td>May 2022</td>\n","      <td>9</td>\n","      <td>9</td>\n","      <td>9\\t\\t\\t\\t\\t\\t\\t</td>\n","      <td>9</td>\n","      <td>8</td>\n","      <td>[[Coffee by Design], [[Blind Assessment: ], Br...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>93</td>\n","      <td>Coffee by Design</td>\n","      <td>Kenya Kahunyo AA</td>\n","      <td>Portland, Maine</td>\n","      <td>Nyeri growing region, south-central Kenya</td>\n","      <td>Medium-Light</td>\n","      <td>59/76</td>\n","      <td>$22.00/16 ounces</td>\n","      <td>May 2022</td>\n","      <td>9</td>\n","      <td>9</td>\n","      <td>8\\t\\t\\t\\t\\t\\t\\t</td>\n","      <td>9</td>\n","      <td>8</td>\n","      <td>[[Coffee by Design], [[Blind Assessment: ], Cr...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>93</td>\n","      <td>Coffee by Design</td>\n","      <td>Honduras COMSA Oscar Omar Alonzo</td>\n","      <td>Portland, Maine</td>\n","      <td>Marcala, Honduras</td>\n","      <td>Medium-Light</td>\n","      <td>58/74</td>\n","      <td>$18.50/12 ounces</td>\n","      <td>May 2022</td>\n","      <td>9</td>\n","      <td>8</td>\n","      <td>9\\t\\t\\t\\t\\t\\t\\t</td>\n","      <td>9</td>\n","      <td>8</td>\n","      <td>[[Coffee by Design], [[Blind Assessment: ], A ...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>92</td>\n","      <td>Coffee by Design</td>\n","      <td>Rwanda Gasharu Natural</td>\n","      <td>Portland, Maine</td>\n","      <td>Nyamasheke District, Rwanda</td>\n","      <td>Medium-Light</td>\n","      <td>58/76</td>\n","      <td>$23.00/12 ounces</td>\n","      <td>May 2022</td>\n","      <td>8</td>\n","      <td>8</td>\n","      <td>9\\t\\t\\t\\t\\t\\t\\t</td>\n","      <td>9</td>\n","      <td>8</td>\n","      <td>[[Coffee by Design], [[Blind Assessment: ], De...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>97</td>\n","      <td>PT's Coffee Roasting Co.</td>\n","      <td>Yemen Haraaz Red Mahal Aqeeq ul Station Natural</td>\n","      <td>Topeka, Kansas</td>\n","      <td>Sharqi, Haraaz, Yemen</td>\n","      <td>Medium-Light</td>\n","      <td>58/76</td>\n","      <td>$35.00/8 ounces</td>\n","      <td>May 2022</td>\n","      <td>10</td>\n","      <td>9</td>\n","      <td>9\\t\\t\\t\\t\\t\\t\\t</td>\n","      <td>10</td>\n","      <td>9</td>\n","      <td>[[PT's Coffee Roasting Co.], [[Blind Assessmen...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>5731</th>\n","      <td>83</td>\n","      <td>The Coffee Beanery</td>\n","      <td>Beanery Blend</td>\n","      <td>Flushing, Michigan</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>February 1997</td>\n","      <td>8</td>\n","      <td>NaN</td>\n","      <td>7\\t\\t\\t\\t\\t\\t\\t</td>\n","      <td>7</td>\n","      <td>NaN</td>\n","      <td>[[The Coffee Beanery], [[Blind Assessment: ], ...</td>\n","    </tr>\n","    <tr>\n","      <th>5732</th>\n","      <td>81</td>\n","      <td>Starbucks Coffee</td>\n","      <td>House Blend</td>\n","      <td>Seattle, Washington</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>February 1997</td>\n","      <td>7</td>\n","      <td>NaN</td>\n","      <td>6\\t\\t\\t\\t\\t\\t\\t</td>\n","      <td>8</td>\n","      <td>NaN</td>\n","      <td>[[Starbucks Coffee], [[Blind Assessment: ], Th...</td>\n","    </tr>\n","    <tr>\n","      <th>5733</th>\n","      <td>75</td>\n","      <td>Peerless Coffee</td>\n","      <td>President’s Private Blend</td>\n","      <td>Oakland, California</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>February 1997</td>\n","      <td>6</td>\n","      <td>NaN</td>\n","      <td>6\\t\\t\\t\\t\\t\\t\\t</td>\n","      <td>5</td>\n","      <td>NaN</td>\n","      <td>[[Peerless Coffee], [[Blind Assessment: ], Giv...</td>\n","    </tr>\n","    <tr>\n","      <th>5734</th>\n","      <td>74</td>\n","      <td>Gevalia</td>\n","      <td>Traditional Roast</td>\n","      <td>Des Moines, Iowa</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>February 1997</td>\n","      <td>7</td>\n","      <td>NaN</td>\n","      <td>6\\t\\t\\t\\t\\t\\t\\t</td>\n","      <td>6</td>\n","      <td>NaN</td>\n","      <td>[[Gevalia], [[Blind Assessment: ], For such a ...</td>\n","    </tr>\n","    <tr>\n","      <th>5735</th>\n","      <td>68</td>\n","      <td>Café Godiva</td>\n","      <td>Special Roast</td>\n","      <td>Clinton, Connecticut</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>February 1997</td>\n","      <td>5</td>\n","      <td>NaN</td>\n","      <td>4\\t\\t\\t\\t\\t\\t\\t</td>\n","      <td>5</td>\n","      <td>NaN</td>\n","      <td>[[Café Godiva], [[Blind Assessment: ], This co...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5736 rows × 15 columns</p>\n","</div>"],"text/plain":["     coffee_score       coffee_roaster_name  \\\n","0              94          Coffee by Design   \n","1              93          Coffee by Design   \n","2              93          Coffee by Design   \n","3              92          Coffee by Design   \n","4              97  PT's Coffee Roasting Co.   \n","...           ...                       ...   \n","5731           83        The Coffee Beanery   \n","5732           81          Starbucks Coffee   \n","5733           75           Peerless Coffee   \n","5734           74                   Gevalia   \n","5735           68               Café Godiva   \n","\n","                                     coffee_bean_name      roaster_location  \\\n","0             Costa Rica Naranjo Danilo Salazar Arias       Portland, Maine   \n","1                                    Kenya Kahunyo AA       Portland, Maine   \n","2                    Honduras COMSA Oscar Omar Alonzo       Portland, Maine   \n","3                              Rwanda Gasharu Natural       Portland, Maine   \n","4     Yemen Haraaz Red Mahal Aqeeq ul Station Natural        Topeka, Kansas   \n","...                                               ...                   ...   \n","5731                                    Beanery Blend    Flushing, Michigan   \n","5732                                      House Blend   Seattle, Washington   \n","5733                        President’s Private Blend   Oakland, California   \n","5734                                Traditional Roast      Des Moines, Iowa   \n","5735                                    Special Roast  Clinton, Connecticut   \n","\n","                                  coffee_origin   roast_level agtron  \\\n","0                          Alajuela, Costa Rica  Medium-Light  60/77   \n","1     Nyeri growing region, south-central Kenya  Medium-Light  59/76   \n","2                             Marcala, Honduras  Medium-Light  58/74   \n","3                   Nyamasheke District, Rwanda  Medium-Light  58/76   \n","4                         Sharqi, Haraaz, Yemen  Medium-Light  58/76   \n","...                                         ...           ...    ...   \n","5731                                        NaN           NaN    NaN   \n","5732                                        NaN           NaN    NaN   \n","5733                                        NaN           NaN    NaN   \n","5734                                        NaN           NaN    NaN   \n","5735                                        NaN           NaN    NaN   \n","\n","        estimate_price    review_date aroma acidity_or_structure  \\\n","0     $23.00/12 ounces       May 2022     9                    9   \n","1     $22.00/16 ounces       May 2022     9                    9   \n","2     $18.50/12 ounces       May 2022     9                    8   \n","3     $23.00/12 ounces       May 2022     8                    8   \n","4      $35.00/8 ounces       May 2022    10                    9   \n","...                ...            ...   ...                  ...   \n","5731               NaN  February 1997     8                  NaN   \n","5732               NaN  February 1997     7                  NaN   \n","5733               NaN  February 1997     6                  NaN   \n","5734               NaN  February 1997     7                  NaN   \n","5735               NaN  February 1997     5                  NaN   \n","\n","                 body flavor aftertaste  \\\n","0     9\\t\\t\\t\\t\\t\\t\\t      9          8   \n","1     8\\t\\t\\t\\t\\t\\t\\t      9          8   \n","2     9\\t\\t\\t\\t\\t\\t\\t      9          8   \n","3     9\\t\\t\\t\\t\\t\\t\\t      9          8   \n","4     9\\t\\t\\t\\t\\t\\t\\t     10          9   \n","...               ...    ...        ...   \n","5731  7\\t\\t\\t\\t\\t\\t\\t      7        NaN   \n","5732  6\\t\\t\\t\\t\\t\\t\\t      8        NaN   \n","5733  6\\t\\t\\t\\t\\t\\t\\t      5        NaN   \n","5734  6\\t\\t\\t\\t\\t\\t\\t      6        NaN   \n","5735  4\\t\\t\\t\\t\\t\\t\\t      5        NaN   \n","\n","                                                   text  \n","0     [[Coffee by Design], [[Blind Assessment: ], Br...  \n","1     [[Coffee by Design], [[Blind Assessment: ], Cr...  \n","2     [[Coffee by Design], [[Blind Assessment: ], A ...  \n","3     [[Coffee by Design], [[Blind Assessment: ], De...  \n","4     [[PT's Coffee Roasting Co.], [[Blind Assessmen...  \n","...                                                 ...  \n","5731  [[The Coffee Beanery], [[Blind Assessment: ], ...  \n","5732  [[Starbucks Coffee], [[Blind Assessment: ], Th...  \n","5733  [[Peerless Coffee], [[Blind Assessment: ], Giv...  \n","5734  [[Gevalia], [[Blind Assessment: ], For such a ...  \n","5735  [[Café Godiva], [[Blind Assessment: ], This co...  \n","\n","[5736 rows x 15 columns]"]},"execution_count":369,"metadata":{},"output_type":"execute_result"}],"source":["df_columns = ['coffee_score', 'coffee_roaster_name','coffee_bean_name', 'roaster_location', 'coffee_origin' ,\\\n","    'roast_level', 'agtron', 'estimate_price', 'review_date', 'aroma', 'acidity_or_structure', 'body', 'flavor', 'aftertaste', 'text']\n","coffee_df = pd.DataFrame(columns = df_columns)\n","\n","row_index = 0\n","for url in url_each_coffee:\n","    req = Request(url , headers={'User-Agent': 'Mozilla/5.0'})\n","\n","    webpage = urlopen(req).read()\n","    page_soup = soup(webpage, \"html.parser\")\n","\n","    coffee_rating = page_soup.findAll(\"span\",\"review-template-rating\")\n","    for rating in coffee_rating:\n","        coffee_df.loc[row_index, 'coffee_score'] = rating.text\n","\n","    coffee_roaster = page_soup.findAll(\"p\",\"review-roaster\")\n","    for roaster in coffee_roaster:\n","        coffee_df.loc[row_index, 'coffee_roaster_name'] = roaster.text\n","\n","    coffee_name = page_soup.findAll(\"h1\",\"review-title\")\n","    for name in coffee_name:\n","        coffee_df.loc[row_index, 'coffee_bean_name'] = name.text\n","\n","    coffee_table = page_soup.findAll(\"table\",\"review-template-table\")\n","    for row in coffee_table:\n","        try:\n","            if \"Roaster Location:\" in row.find_all('td')[0]:\n","                coffee_df.loc[row_index, 'roaster_location'] = row.find_all('td')[1].text\n","        except:\n","            continue\n","\n","        try:\n","            if \"Coffee Origin:\" in row.find_all('td')[2]:\n","                coffee_df.loc[row_index, 'coffee_origin'] = row.find_all('td')[3].text\n","        except:\n","            continue\n","        \n","        try:\n","            if \"Roast Level:\" in row.find_all('td')[4]:\n","                coffee_df.loc[row_index, 'roast_level'] = row.find_all('td')[5].text\n","        except:\n","            continue\n","\n","        try:\n","            if \"Agtron:\" in row.find_all('td')[6]:\n","                coffee_df.loc[row_index, 'agtron'] = row.find_all('td')[7].text\n","        except:\n","            continue\n","\n","        try:\n","            if \"Est. Price:\" in row.find_all('td')[8]:\n","                coffee_df.loc[row_index, 'estimate_price'] = row.find_all('td')[9].text\n","        except:\n","            continue\n","\n","        try:\n","            if \"Review Date:\" in row.find_all('td')[0]:\n","                coffee_df.loc[row_index, 'review_date'] = row.find_all('td')[1].text\n","        except:\n","            continue\n","\n","        try:\n","            if \"Aroma:\" in row.find_all('td')[2]:\n","                coffee_df.loc[row_index, 'aroma'] = row.find_all('td')[3].text\n","        except:\n","            continue\n","        \n","        try:\n","            if \"Acidity/Structure:\" in row.find_all('td')[4]:\n","                coffee_df.loc[row_index, 'acidity_or_structure'] = row.find_all('td')[5].text\n","        except:\n","            continue\n","        \n","        try:\n","            if \"Body:\" in row.find_all('td')[6]:\n","                coffee_df.loc[row_index, 'body'] = row.find_all('td')[7].text\n","        except:\n","            continue\n","        \n","        try:\n","            if \"Flavor:\" in row.find_all('td')[8]:\n","                coffee_df.loc[row_index, 'flavor'] = row.find_all('td')[9].text\n","        except:\n","            continue\n","        \n","        try:\n","            if \"Aftertaste:\" in row.find_all('td')[-2]:\n","                coffee_df.loc[row_index, 'aftertaste'] = row.find_all('td')[-1].text\n","        except:\n","            continue\n","        \n","\n","    coffee_text = page_soup.findAll(\"div\",\"review-template\")\n","    for name in coffee_text:\n","        coffee_df.loc[row_index, 'text'] = name.find_all('p')\n","    row_index+=1\n","\n","coffee_df"]},{"cell_type":"markdown","metadata":{},"source":["# Step 3: Prepare Data for Consumption <a class=\"anchor\" id=\"Prepare-Data-for-Consumption\"></a>"]},{"cell_type":"markdown","metadata":{},"source":["## 3.1 Import Libraries <a class=\"anchor\" id=\"Import-Libraries\"></a>"]},{"cell_type":"markdown","metadata":{},"source":["## 3.11 Load Data Modelling Libraries <a class=\"anchor\" id=\"Load-Data-Modelling-Libraries\"></a>"]},{"cell_type":"markdown","metadata":{},"source":["## 3.2 Meet and Greet Data <a class=\"anchor\" id=\"Meet-and-Greet-Data\"></a>"]},{"cell_type":"markdown","metadata":{},"source":["1)The FGM variable is outcome or dependent variable. It is a binary nominal datatype of 1 for make and 0 for missed. \n","All other variables are potential or independent variables. \n","Its important to note, more predictor variables do not make a better model, but the right variables.\n","<br>\n","2)The GameID, match, win, Final_margin, shot_number, and PTS are assumed to be random unique identifiers, that have no impact on the outcome veribale. Thus, they will be excluded from analysis.\n","<br>\n","4)The Name and shot_number variable are nominal datatype. It could be used in feature engineering to derive the who the best defender is, the hot-hand hypothesis, etc. Since these variables already exist, we'll make use of it to see if player makes a difference.\n","<br>\n","5)The Location and PTS_type variables are a nominal datatype. They will be converted to dummy variables for mathematical calculations.\n","<br>\n","6)The game_clock, shot_clock, dribbles,  touch_time, shot_distance, and closet_defender_distance variable are continuous quantitative datatypes.\n"]},{"cell_type":"markdown","metadata":{},"source":["### 3.21 The 4 C's of Data Cleaning: Correcting, Completing, Creating, and Converting <a class=\"anchor\" id=\"4C\"></a>"]},{"cell_type":"markdown","metadata":{},"source":["### 3.22 Clean Data <a class=\"anchor\" id=\"Clean-Data\"></a>"]},{"cell_type":"markdown","metadata":{},"source":["### 3.23 Convert Formats <a class=\"anchor\" id=\"Convert-Formats\"></a>"]},{"cell_type":"markdown","metadata":{},"source":["### 3.24 Da-Double Check Cleaned Data <a class=\"anchor\" id=\"Da-Double-Check-Cleaned-Data\"></a>"]},{"cell_type":"markdown","metadata":{},"source":["### 3.25 Split Training and Testing Data <a class=\"anchor\" id=\"Split-Training-and-Testing-Data\"></a>"]},{"cell_type":"markdown","metadata":{},"source":["# Step 4: Perform Exploratory Analysis with Statistics <a class=\"anchor\" id=\"Perform-Exploratory-Analysis-with-Statistics\"></a>"]},{"cell_type":"markdown","metadata":{},"source":["# Step 5: Model Data <a class=\"anchor\" id=\"Model-Data\"></a>"]},{"cell_type":"markdown","metadata":{},"source":["## 5.1 Evaluate Model Performance <a class=\"anchor\" id=\"Evaluate-Model-Performance\"></a>"]},{"cell_type":"markdown","metadata":{},"source":["### 5.11 Model Performance with Cross-Validation (CV) <a class=\"anchor\" id=\"CV\"></a>"]},{"cell_type":"markdown","metadata":{},"source":["### 5.12 Tune Model with Hyper-Parameters <a class=\"anchor\" id=\"Tune-Model-with-Hyper-Parameters\"></a>"]},{"cell_type":"markdown","metadata":{},"source":["### 5.13 Tune Model with Feature Selection <a class=\"anchor\" id=\"Tune-Model-with-Feature-Selection\"></a>"]},{"cell_type":"markdown","metadata":{},"source":["# Step 6: Validate and Implement <a class=\"anchor\" id=\"Validate-and-Implement\"></a>"]},{"cell_type":"markdown","metadata":{},"source":["# Step 7: Optimize and Strategize<a class=\"anchor\" id=\"Optimize-and-Strategize\"></a>"]},{"cell_type":"markdown","metadata":{},"source":["### Conclusion\n","Iteration one of the Data Science Framework, seems to converge on 0.77990 submission accuracy. Using the same dataset and different implementation of a random forest (adaboost,decision tree, gradient boost, xgboost, etc.) with tuning does not exceed the 0.77990 submission accuracy. Interesting for this dataset, the simple random forest algorithm had the best default submission score and with tuning achieved the same best accuracy score.\n","\n","While no general conclusions can be made from testing a handful of algorithms on a single dataset, there are several observations on the mentioned dataset.\n","\n","The train dataset has a different distribution than the test/validation dataset and population. This created wide margins between the cross validation (CV) accuracy score .\n","Given the same dataset, random forest based algorithms, seemed to converge on the same accuracy score after proper tuning.\n","Despite tuning, no machine learning algorithm, exceeded the homemade algorithm. The author will theorize, that for small datasets, a manmade algorithm is the bar to beat.\n","With that in mind, for iteration two, I would spend more time on preprocessing and feature engineering. In order to better align the CV score and improve the overall accuracy."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"interpreter":{"hash":"2700375e02ad74d7fa19bf39b9bbaacee623ff18e8d83a1c706494d7922e527a"},"kernelspec":{"display_name":"Python (learn-env)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"}},"nbformat":4,"nbformat_minor":4}
